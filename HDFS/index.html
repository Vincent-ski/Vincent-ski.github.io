<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/cute.jpeg">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/cute.jpeg">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/cute.jpeg">
  <link rel="mask-icon" href="/images/cute.jpeg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="HDFS基础">
<meta property="og:type" content="article">
<meta property="og:title" content="HDFS">
<meta property="og:url" content="http://example.com/HDFS/index.html">
<meta property="og:site_name" content="Vincent&#39;s Learning Journey">
<meta property="og:description" content="HDFS基础">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/HDFS/38.png">
<meta property="og:image" content="http://example.com/HDFS/39.png">
<meta property="og:image" content="http://example.com/HDFS/40.png">
<meta property="og:image" content="http://example.com/HDFS/41.png">
<meta property="og:image" content="http://example.com/HDFS/42.png">
<meta property="og:image" content="http://example.com/HDFS/43.png">
<meta property="og:image" content="http://example.com/HDFS/44.png">
<meta property="og:image" content="http://example.com/HDFS/45.png">
<meta property="og:image" content="http://example.com/HDFS/46.png">
<meta property="og:image" content="http://example.com/HDFS/47.png">
<meta property="og:image" content="http://example.com/HDFS/48.png">
<meta property="og:image" content="http://example.com/HDFS/49.png">
<meta property="og:image" content="http://example.com/HDFS/50.png">
<meta property="og:image" content="http://example.com/HDFS/51.png">
<meta property="og:image" content="http://example.com/HDFS/52.png">
<meta property="og:image" content="http://example.com/HDFS/53.png">
<meta property="og:image" content="http://example.com/HDFS/54.png">
<meta property="og:image" content="http://example.com/HDFS/55.png">
<meta property="article:published_time" content="2021-12-24T10:46:41.000Z">
<meta property="article:modified_time" content="2021-12-28T13:07:24.877Z">
<meta property="article:author" content="Vincent">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/HDFS/38.png">

<link rel="canonical" href="http://example.com/HDFS/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>HDFS | Vincent's Learning Journey</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Vincent's Learning Journey</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">DayDayUp</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section">Home</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section">Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section">Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger">Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/HDFS/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/cute.jpeg">
      <meta itemprop="name" content="Vincent">
      <meta itemprop="description" content="nice">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Vincent's Learning Journey">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          HDFS
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-12-24 18:46:41" itemprop="dateCreated datePublished" datetime="2021-12-24T18:46:41+08:00">2021-12-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-12-28 21:07:24" itemprop="dateModified" datetime="2021-12-28T21:07:24+08:00">2021-12-28</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Hadoop/" itemprop="url" rel="index"><span itemprop="name">Hadoop</span></a>
                </span>
            </span>

          
            <div class="post-description">HDFS基础</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="HDFS概述"><a href="#HDFS概述" class="headerlink" title="HDFS概述"></a>HDFS概述</h1><p><img src="/HDFS/38.png" alt="38"></p>
<h1 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h1><p><img src="/HDFS/39.png" alt="39"></p>
<p><img src="/HDFS/40.png" alt="40"></p>
<h1 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h1><p><img src="/HDFS/41.png" alt="41"></p>
<p><img src="/HDFS/42.png" alt="42"></p>
<h1 id="文件块大小"><a href="#文件块大小" class="headerlink" title="文件块大小"></a>文件块大小</h1><p><img src="/HDFS/43.png" alt="43"></p>
<p><img src="/HDFS/44.png" alt="44"></p>
<h1 id="Shell操作"><a href="#Shell操作" class="headerlink" title="Shell操作"></a>Shell操作</h1><p>bin/hadoop fs 具体命令   </p>
<p>bin/hdfs dfs 具体命令</p>
<p>两个是完全相同的。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">//-help</span><br><span class="line">hadoop fs -help rm</span><br><span class="line"></span><br><span class="line">//-ls</span><br><span class="line">hadoop fs -ls /</span><br><span class="line"></span><br><span class="line">//-mkdir</span><br><span class="line">hadoop fs -mkdir -p /sanguo/shuguo</span><br><span class="line"></span><br><span class="line">//-moveFromLocal	从本地剪切粘贴到HDFS</span><br><span class="line">hadoop fs -moveFromLocal ./kongming.txt  /sanguo/shuguo</span><br><span class="line"></span><br><span class="line">//-appendToFile	追加一个文件到已经存在的文件末尾</span><br><span class="line">hadoop fs -appendToFile liubei.txt /sanguo/shuguo/kongming.txt</span><br><span class="line"></span><br><span class="line">//-cat 显示文件内容</span><br><span class="line">hadoop fs -cat /sanguo/shuguo/kongming.txt</span><br><span class="line"></span><br><span class="line">//-chgrp 、-chmod、-chown Linux文件系统中的用法一样，修改文件所属权限</span><br><span class="line">hadoop fs	-chmod	666	/sanguo/shuguo/kongming.txt</span><br><span class="line">hadoop fs	-chown	vincent:vincent	/sanguo/shuguo/kongming.txt</span><br><span class="line"></span><br><span class="line">//-copyFromLocal	从本地文件系统中拷贝文件到HDFS路径去</span><br><span class="line">hadoop fs -copyFromLocal README.txt /</span><br><span class="line"></span><br><span class="line">//-put 等同于copyFromLocal</span><br><span class="line">hadoop fs -put ./zaiyiqi.txt /user/vincent/test/</span><br><span class="line"></span><br><span class="line">//-copyToLocal 从HDFS拷贝到本地</span><br><span class="line">hadoop fs -copyToLocal /sanguo/shuguo/kongming.txt ./</span><br><span class="line"></span><br><span class="line">//-get 等同于copyToLocal，就是从HDFS下载文件到本地</span><br><span class="line">hadoop fs -get /sanguo/shuguo/kongming.txt ./</span><br><span class="line"></span><br><span class="line">//-cp 从HDFS的一个路径拷贝到HDFS的另一个路径</span><br><span class="line">hadoop fs -cp /sanguo/shuguo/kongming.txt /zhuge.txt</span><br><span class="line"></span><br><span class="line">//-mv 在HDFS目录中移动文件</span><br><span class="line">hadoop fs -mv /zhuge.txt /sanguo/shuguo/</span><br><span class="line"></span><br><span class="line">//-getmerge 合并下载多个文件，比如HDFS的目录 /user/vincent/test下有多个文件:log1, log2,log3,...</span><br><span class="line">hadoop fs -getmerge /user/vincent/test/* ./zaiyiqi.txt</span><br><span class="line"></span><br><span class="line">//-tail 显示一个文件的末尾</span><br><span class="line">hadoop fs -tail /sanguo/shuguo/kongming.txt</span><br><span class="line"></span><br><span class="line">//-rm 删除文件或文件夹</span><br><span class="line">hadoop fs -rm /user/vincent/test/jinlian2.txt</span><br><span class="line"></span><br><span class="line">//-rmdir 删除空目录</span><br><span class="line">hadoop fs -rmdir /test</span><br><span class="line"></span><br><span class="line">//-du 统计文件夹的大小信息</span><br><span class="line">hadoop fs -du -s -h /user/vincent/test</span><br><span class="line"></span><br><span class="line">//-setrep 设置HDFS中文件的副本数量</span><br><span class="line">hadoop fs -setrep 5 /README.txt			//README.txt 存了5份</span><br><span class="line"></span><br><span class="line">//判断文件、路径是否存在 参数有-e -f等</span><br><span class="line">hadoop fs -test /aaa/bbb</span><br></pre></td></tr></table></figure>

<h1 id="HDFS客户端权限"><a href="#HDFS客户端权限" class="headerlink" title="HDFS客户端权限"></a>HDFS客户端权限</h1><p>hadoop默认情况下开启了权限检查，且默认使用dir.who作为http访问的静态用户,因此可通过关闭权限检查或者配置http访问的静态用户为vincent，二选一即可。</p>
<p>在core-site.xml中修改http访问的静态用户为vincent：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.http.staticuser.user<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>vincent<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>在hdfs-site.xml中关闭权限检查：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.permissions.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h1 id="HDFS客户端操作"><a href="#HDFS客户端操作" class="headerlink" title="HDFS客户端操作"></a>HDFS客户端操作</h1><h2 id="准备操作"><a href="#准备操作" class="headerlink" title="准备操作"></a>准备操作</h2><p>1）配置Hadoop环境变量</p>
<p>2）创建maven</p>
<p>3）导入依赖</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>4.12<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.logging.log4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>log4j-slf4j-impl<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.12.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.1.3<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>项目的src/main/resources目录下，新建一个文件，命名为“log4j2.xml”，在文件中填入：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">Configuration</span> <span class="attr">status</span>=<span class="string">&quot;error&quot;</span> <span class="attr">strict</span>=<span class="string">&quot;true&quot;</span> <span class="attr">name</span>=<span class="string">&quot;XMLConfig&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">Appenders</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 类型名为Console，名称为必须属性 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">Appender</span> <span class="attr">type</span>=<span class="string">&quot;Console&quot;</span> <span class="attr">name</span>=<span class="string">&quot;STDOUT&quot;</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!-- 布局为PatternLayout的方式，</span></span><br><span class="line"><span class="comment">            输出样式为[INFO] [2018-01-22 17:34:01][org.test.Console]I&#x27;m here --&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">Layout</span> <span class="attr">type</span>=<span class="string">&quot;PatternLayout&quot;</span></span></span><br><span class="line"><span class="tag">                    <span class="attr">pattern</span>=<span class="string">&quot;[%p] [%d&#123;yyyy-MM-dd HH:mm:ss&#125;][%c&#123;10&#125;]%m%n&quot;</span> /&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">Appender</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;/<span class="name">Appenders</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">Loggers</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 可加性为false --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">Logger</span> <span class="attr">name</span>=<span class="string">&quot;test&quot;</span> <span class="attr">level</span>=<span class="string">&quot;info&quot;</span> <span class="attr">additivity</span>=<span class="string">&quot;false&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">AppenderRef</span> <span class="attr">ref</span>=<span class="string">&quot;STDOUT&quot;</span> /&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">Logger</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- root loggerConfig设置 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">Root</span> <span class="attr">level</span>=<span class="string">&quot;info&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">AppenderRef</span> <span class="attr">ref</span>=<span class="string">&quot;STDOUT&quot;</span> /&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">Root</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">Loggers</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">Configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>4）创建包名 com.vincent.hdfs</p>
<p>5）创建HdfsClient类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HdfsClient</span></span>&#123;	</span><br><span class="line">   <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testHdfsClient</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">        <span class="comment">//1. 创建HDFS客户端对象,传入uri， configuration , user</span></span><br><span class="line">        FileSystem fileSystem =</span><br><span class="line">                FileSystem.get(URI.create(<span class="string">&quot;hdfs://linux1:9820&quot;</span>), <span class="keyword">new</span> Configuration(), <span class="string">&quot;vincent&quot;</span>);</span><br><span class="line">        <span class="comment">//2. 操作集群</span></span><br><span class="line">        <span class="comment">// 例如：在集群的/目录下创建 testHDFS目录</span></span><br><span class="line">        fileSystem.mkdirs(<span class="keyword">new</span> Path(<span class="string">&quot;/testHDFS&quot;</span>));</span><br><span class="line">        <span class="comment">//3. 关闭资源</span></span><br><span class="line">        fileSystem.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="API操作"><a href="#API操作" class="headerlink" title="API操作"></a>API操作</h2><h3 id="HDFS文件上传（测试参数优先级）"><a href="#HDFS文件上传（测试参数优先级）" class="headerlink" title="HDFS文件上传（测试参数优先级）"></a>HDFS文件上传（测试参数优先级）</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testCopyFromLocalFile</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException, URISyntaxException </span>&#123;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 1 获取文件系统</span></span><br><span class="line">		Configuration configuration = <span class="keyword">new</span> Configuration();</span><br><span class="line">    <span class="comment">// 设置副本数为2个</span></span><br><span class="line">		configuration.set(<span class="string">&quot;dfs.replication&quot;</span>, <span class="string">&quot;2&quot;</span>);</span><br><span class="line">		FileSystem fs = FileSystem.get(<span class="keyword">new</span> URI(<span class="string">&quot;hdfs://linux1:9820&quot;</span>), configuration, <span class="string">&quot;vincent&quot;</span>);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 2 上传文件</span></span><br><span class="line">		fs.copyFromLocalFile(<span class="keyword">new</span> Path(<span class="string">&quot;e:/banzhang.txt&quot;</span>), <span class="keyword">new</span> Path(<span class="string">&quot;/banzhang.txt&quot;</span>));</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 3 关闭资源</span></span><br><span class="line">		fs.close();</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在项目的resources中新建hdfs-site.xml文件，并将如下内容拷贝进去，再次测试</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>参数优先级：</p>
<p>（1）客户端代码中设置的值 &gt;（2）ClassPath下的用户自定义配置文件 &gt;（3）然后是服务器的自定义配置(xxx-site.xml) &gt;（4）服务器的默认配置(xxx-default.xml)</p>
<h3 id="HDFS文件下载"><a href="#HDFS文件下载" class="headerlink" title="HDFS文件下载"></a>HDFS文件下载</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testCopyToLocalFile</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException, URISyntaxException</span>&#123;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 1 获取文件系统</span></span><br><span class="line">		Configuration configuration = <span class="keyword">new</span> Configuration();</span><br><span class="line">		FileSystem fs = FileSystem.get(<span class="keyword">new</span> URI(<span class="string">&quot;hdfs://linux1:9820&quot;</span>), configuration, <span class="string">&quot;vincent&quot;</span>);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 2 执行下载操作</span></span><br><span class="line">		<span class="comment">// boolean delSrc 指是否将原文件删除</span></span><br><span class="line">		<span class="comment">// Path src 指要下载的文件路径</span></span><br><span class="line">		<span class="comment">// Path dst 指将文件下载到的路径</span></span><br><span class="line">		<span class="comment">// boolean useRawLocalFileSystem 是否开启文件校验</span></span><br><span class="line">		fs.copyToLocalFile(<span class="keyword">false</span>, <span class="keyword">new</span> Path(<span class="string">&quot;/banzhang.txt&quot;</span>), <span class="keyword">new</span> Path(<span class="string">&quot;e:/banhua.txt&quot;</span>), <span class="keyword">true</span>);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 3 关闭资源</span></span><br><span class="line">		fs.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="HDFS文件夹删除"><a href="#HDFS文件夹删除" class="headerlink" title="HDFS文件夹删除"></a>HDFS文件夹删除</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testDelete</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException, URISyntaxException</span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 1 获取文件系统</span></span><br><span class="line">	Configuration configuration = <span class="keyword">new</span> Configuration();</span><br><span class="line">	FileSystem fs = FileSystem.get(<span class="keyword">new</span> URI(<span class="string">&quot;hdfs://linux1:9820&quot;</span>), configuration, <span class="string">&quot;vincent&quot;</span>);</span><br><span class="line">		</span><br><span class="line">	<span class="comment">// 2 执行删除</span></span><br><span class="line">	fs.delete(<span class="keyword">new</span> Path(<span class="string">&quot;/0213/&quot;</span>), <span class="keyword">true</span>);</span><br><span class="line">		</span><br><span class="line">	<span class="comment">// 3 关闭资源</span></span><br><span class="line">	fs.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="HDFS文件名更改-移动"><a href="#HDFS文件名更改-移动" class="headerlink" title="HDFS文件名更改/移动"></a>HDFS文件名更改/移动</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testRename</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException, URISyntaxException</span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 1 获取文件系统</span></span><br><span class="line">	Configuration configuration = <span class="keyword">new</span> Configuration();</span><br><span class="line">	FileSystem fs = FileSystem.get(<span class="keyword">new</span> URI(<span class="string">&quot;hdfs://linux1:9820&quot;</span>), configuration, <span class="string">&quot;vincent&quot;</span>); </span><br><span class="line">		</span><br><span class="line">	<span class="comment">// 2 修改文件名称</span></span><br><span class="line">	fs.rename(<span class="keyword">new</span> Path(<span class="string">&quot;/banzhang.txt&quot;</span>), <span class="keyword">new</span> Path(<span class="string">&quot;/banhua.txt&quot;</span>));</span><br><span class="line">		</span><br><span class="line">	<span class="comment">// 3 关闭资源</span></span><br><span class="line">	fs.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="HDFS文件详情查看"><a href="#HDFS文件详情查看" class="headerlink" title="HDFS文件详情查看"></a>HDFS文件详情查看</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testListFiles</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException, URISyntaxException</span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 1获取文件系统</span></span><br><span class="line">	Configuration configuration = <span class="keyword">new</span> Configuration();</span><br><span class="line">	FileSystem fs = FileSystem.get(<span class="keyword">new</span> URI(<span class="string">&quot;hdfs://linux1:9820&quot;</span>), configuration, <span class="string">&quot;vincent&quot;</span>); </span><br><span class="line">		</span><br><span class="line">	<span class="comment">// 2 获取文件详情</span></span><br><span class="line">	RemoteIterator&lt;LocatedFileStatus&gt; listFiles = fs.listFiles(<span class="keyword">new</span> Path(<span class="string">&quot;/&quot;</span>), <span class="keyword">true</span>);</span><br><span class="line">		</span><br><span class="line">	<span class="keyword">while</span>(listFiles.hasNext())&#123;</span><br><span class="line">		LocatedFileStatus status = listFiles.next();</span><br><span class="line">			</span><br><span class="line">		<span class="comment">// 输出详情</span></span><br><span class="line">		<span class="comment">// 文件名称</span></span><br><span class="line">		System.out.println(status.getPath().getName());</span><br><span class="line">		<span class="comment">// 长度</span></span><br><span class="line">		System.out.println(status.getLen());</span><br><span class="line">		<span class="comment">// 权限</span></span><br><span class="line">		System.out.println(status.getPermission());</span><br><span class="line">		<span class="comment">// 分组</span></span><br><span class="line">		System.out.println(status.getGroup());</span><br><span class="line">			</span><br><span class="line">		<span class="comment">// 获取存储的块信息</span></span><br><span class="line">		BlockLocation[] blockLocations = status.getBlockLocations();</span><br><span class="line">			</span><br><span class="line">		<span class="keyword">for</span> (BlockLocation blockLocation : blockLocations) &#123;</span><br><span class="line">				</span><br><span class="line">			<span class="comment">// 获取块存储的主机节点</span></span><br><span class="line">			String[] hosts = blockLocation.getHosts();</span><br><span class="line">				</span><br><span class="line">			<span class="keyword">for</span> (String host : hosts) &#123;</span><br><span class="line">				System.out.println(host);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">			</span><br><span class="line">		System.out.println(<span class="string">&quot;-----------漂亮的分割线----------&quot;</span>);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 3 关闭资源</span></span><br><span class="line">fs.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="HDFS文件和文件夹判断"><a href="#HDFS文件和文件夹判断" class="headerlink" title="HDFS文件和文件夹判断"></a>HDFS文件和文件夹判断</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testListStatus</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException, URISyntaxException</span>&#123;</span><br><span class="line">        </span><br><span class="line">    <span class="comment">// 1 获取文件配置信息</span></span><br><span class="line">    Configuration configuration = <span class="keyword">new</span> Configuration();</span><br><span class="line">    FileSystem fs = FileSystem.get(<span class="keyword">new</span> URI(<span class="string">&quot;hdfs://linux1:9820&quot;</span>), configuration, <span class="string">&quot;vincent&quot;</span>);</span><br><span class="line">        </span><br><span class="line">    <span class="comment">// 2 判断是文件还是文件夹</span></span><br><span class="line">    FileStatus[] listStatus = fs.listStatus(<span class="keyword">new</span> Path(<span class="string">&quot;/&quot;</span>));</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">for</span> (FileStatus fileStatus : listStatus) &#123;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 如果是文件</span></span><br><span class="line">        <span class="keyword">if</span> (fileStatus.isFile()) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;f:&quot;</span>+fileStatus.getPath().getName());</span><br><span class="line">        &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;d:&quot;</span>+fileStatus.getPath().getName());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">        </span><br><span class="line">    <span class="comment">// 3 关闭资源</span></span><br><span class="line">    fs.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="HDFS的数据流"><a href="#HDFS的数据流" class="headerlink" title="HDFS的数据流"></a>HDFS的数据流</h1><h2 id="写入数据"><a href="#写入数据" class="headerlink" title="写入数据"></a>写入数据</h2><p><img src="/HDFS/45.png" alt="45"></p>
<p>1）客户端通过Distributed FileSystem模块向NameNode请求上传文件，NameNode检查目标文件是否已存在，父目录是否存在。</p>
<p>2）NameNode返回是否可以上传。</p>
<p>3）客户端请求第一个 Block上传到哪几个DataNode服务器上。</p>
<p>4）NameNode返回3个DataNode节点，分别为dn1、dn2、dn3。</p>
<p>5）客户端通过FSDataOutputStream模块请求dn1上传数据，dn1收到请求会继续调用dn2，然后dn2调用dn3，将这个通信管道建立完成。</p>
<p>6）dn1、dn2、dn3逐级应答客户端。</p>
<p>7）客户端开始往dn1上传第一个Block（先从磁盘读取数据放到一个本地内存缓存），以Packet为单位，dn1收到一个Packet就会传给dn2，dn2传给dn3；dn1每传一个packet会放入一个应答队列等待应答。</p>
<p>8）当一个Block传输完成之后，客户端再次请求NameNode上传第二个Block的服务器。（重复执行3-7步）。</p>
<h3 id="网络拓扑-节点距离计算"><a href="#网络拓扑-节点距离计算" class="headerlink" title="网络拓扑-节点距离计算"></a>网络拓扑-节点距离计算</h3><p><strong>在HDFS写数据的过程中，NameNode会选择距离待上传数据最近距离的DataNode接收数据</strong>。那么这个最近距离怎么计算呢？</p>
<p>节点距离：两个节点到达最近的共同祖先的距离总和。</p>
<p><img src="/HDFS/46.png" alt="46"></p>
<h3 id="副本节点选择"><a href="#副本节点选择" class="headerlink" title="副本节点选择"></a>副本节点选择</h3><p><img src="/HDFS/47.png" alt="47"></p>
<h3 id="机架感知"><a href="#机架感知" class="headerlink" title="机架感知"></a>机架感知</h3><p>分布式的集群通常包含非常多的机器，由于受到机架槽位和交换机网口的限制，通常大型的分布式集群都会跨好几个机架，由多个机架上的机器共同组成一个分布式集群。机架内的机器之间的网络速度通常都会高于跨机架机器之间的网络速度，并且机架之间机器的网络通信通常受到上层交换机间网络带宽的限制。</p>
<p><strong>Hadoop在设计时考虑到数据的安全与高效，数据文件默认在HDFS上存放三份，存储策略为:</strong></p>
<p>第一个block副本放在<strong>客户端所在的数据节点里</strong>（如果客户端不在集群范围内，则从整个集群中随机选择一个合适的数据节点来存放）。</p>
<p>第二个副本放置在<strong>与第一个副本所在节点相同机架内的其它数据节点上</strong></p>
<p>第三个副本放置在<strong>不同机架的节点上</strong></p>
<p>这样如果本地数据损坏，节点可以从同一机架内的相邻节点拿到数据，速度肯定比从跨机架节点上拿数据要快；<br>同时，如果整个机架的网络出现异常，也能保证在其它机架的节点上找到数据。<br>为了降低整体的带宽消耗和读取延时，HDFS会尽量让读取程序读取离它最近的副本。<br>如果在读取程序的同一个机架上有一个副本，那么就读取该副本。<br>如果一个HDFS集群跨越多个数据中心，那么客户端也将首先读本地数据中心的副本。<br>那么Hadoop是如何确定任意两个节点是位于同一机架，还是跨机架的呢？答案就是机架感知。</p>
<p><strong>默认情况下，hadoop的机架感知是没有被启用的</strong>。所有的机器hadoop都默认在同一个默认的机架下，名为 “/default-rack”，这种情况下，任何一台datanode机器，不管物理上是否属于同一个机架，都会被认为是在同一个机架下，此时，就很容易出现增添机架间网络负载的情况。因为此时hadoop集群的HDFS在选机器的时候，是随机选择的，也就是说，<br>很有可能在写数据时，hadoop将第一块数据block1写到了rack1上，然后随机的选择下将block2写入到了rack2下，<br>此时两个rack之间产生了数据传输的流量，再接下来，在随机的情况下，又将block3重新又写回了rack1，此时，两个rack之间又产生了一次数据流量。</p>
<p>在job处理的数据量非常的大，或者往hadoop推送的数据量非常大的时候，这种情况会造成rack之间的网络流量成倍的上升，成为性能的瓶颈，<br>进而影响作业的性能以至于整个集群的服务。</p>
<p><strong>配置</strong></p>
<p>默认情况下，namenode启动时候日志是这样的：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INFO org<span class="selector-class">.apache</span><span class="selector-class">.hadoop</span><span class="selector-class">.net</span><span class="selector-class">.NetworkTopology</span>: Adding <span class="selector-tag">a</span> new node: /default-rack/ <span class="number">172.16</span>.<span class="number">145.35</span>:<span class="number">50010</span></span><br></pre></td></tr></table></figure>

<p>每个IP 对应的机架ID都是 /default-rack ，说明hadoop的机架感知没有被启用。<br>要将hadoop机架感知的功能启用，配置非常简单，在 NameNode所在节点的/etc/hadoop/conf下的core-site.xml配置文件中配置一个选项:</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>topology.script.file.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>/etc/hadoop/conf/RackAware.py<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>这个配置选项的value指定为一个可执行程序，通常为一个脚本，该脚本接受一个参数，输出一个值。</strong><br>接受的参数通常为某台datanode机器的ip地址，而输出的值通常为该ip地址对应的datanode所在的rack，例如”/rack1”。<br>Namenode启动时，会判断该配置选项是否为空，如果非空，则表示已经启用机架感知的配置，此时namenode会根据配置寻找该脚本，<br>并在接收到每一个datanode的heartbeat时，将该datanode的ip地址作为参数传给该脚本运行，并将得到的输出作为该datanode所属的机架ID，保存到内存的一个map中。</p>
<p>脚本：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/usr/bin/python</span></span><br><span class="line"><span class="meta">#</span><span class="bash">-*-coding:UTF-8 -*-</span></span><br><span class="line">import sys</span><br><span class="line"> </span><br><span class="line">rack = &#123;&quot;NN01&quot;:&quot;rack2&quot;,</span><br><span class="line">        &quot;NN02&quot;:&quot;rack3&quot;,</span><br><span class="line">        &quot;DN01&quot;:&quot;rack4&quot;,</span><br><span class="line">        &quot;DN02&quot;:&quot;rack4&quot;,</span><br><span class="line">        &quot;DN03&quot;:&quot;rack1&quot;,</span><br><span class="line">        &quot;DN04&quot;:&quot;rack3&quot;,</span><br><span class="line">        &quot;DN05&quot;:&quot;rack1&quot;,</span><br><span class="line">        &quot;DN06&quot;:&quot;rack4&quot;,</span><br><span class="line">        &quot;DN07&quot;:&quot;rack1&quot;,</span><br><span class="line">        &quot;DN08&quot;:&quot;rack2&quot;,</span><br><span class="line">        &quot;DN09&quot;:&quot;rack1&quot;,</span><br><span class="line">        &quot;DN10&quot;:&quot;rack2&quot;,</span><br><span class="line">        &quot;172.16.145.32&quot;:&quot;rack2&quot;,</span><br><span class="line">        &quot;172.16.145.33&quot;:&quot;rack3&quot;,</span><br><span class="line">        &quot;172.16.145.34&quot;:&quot;rack4&quot;,</span><br><span class="line">        &quot;172.16.145.35&quot;:&quot;rack4&quot;,</span><br><span class="line">        &quot;172.16.145.36&quot;:&quot;rack1&quot;,</span><br><span class="line">        &quot;172.16.145.37&quot;:&quot;rack3&quot;,</span><br><span class="line">        &quot;172.16.145.38&quot;:&quot;rack1&quot;,</span><br><span class="line">        &quot;172.16.145.39&quot;:&quot;rack4&quot;,</span><br><span class="line">        &quot;172.16.145.40&quot;:&quot;rack1&quot;,</span><br><span class="line">        &quot;172.16.145.41&quot;:&quot;rack2&quot;,</span><br><span class="line">        &quot;172.16.145.42&quot;:&quot;rack1&quot;,</span><br><span class="line">        &quot;172.16.145.43&quot;:&quot;rack2&quot;,</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">if __name__==&quot;__main__&quot;:</span><br><span class="line">    print &quot;/&quot; + rack.get(sys.argv[1],&quot;rack0&quot;)</span><br></pre></td></tr></table></figure>

<p>这样配置后，namenode启动时候日志是这样的：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INFO org<span class="selector-class">.apache</span><span class="selector-class">.hadoop</span><span class="selector-class">.net</span><span class="selector-class">.NetworkTopology</span>: Adding <span class="selector-tag">a</span> new node: /rack4/ <span class="number">172.16</span>.<span class="number">145.35</span>:<span class="number">50010</span></span><br></pre></td></tr></table></figure>

<p>说明hadoop的机架感知已经被启用了。<br>查看HADOOP机架信息命令: <strong>hdfs  dfsadmin  -printTopology</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@NN01 hadoop-hdfs]$ hdfs dfsadmin -printTopology</span><br><span class="line">Rack: /rack1</span><br><span class="line">   172.16.145.36:50010 (DN03)</span><br><span class="line">   172.16.145.38:50010 (DN05)</span><br><span class="line">   172.16.145.40:50010 (DN07)</span><br><span class="line">   172.16.145.42:50010 (DN09)</span><br><span class="line">   172.16.145.44:50010 (DN11)</span><br><span class="line">   172.16.145.54:50010 (DN17)</span><br><span class="line">   172.16.145.56:50010 (DN19)</span><br><span class="line">   172.16.145.58:50010 (DN21)</span><br><span class="line"> </span><br><span class="line">Rack: /rack2</span><br><span class="line">   172.16.145.41:50010 (DN08)</span><br><span class="line">   172.16.145.43:50010 (DN10)</span><br><span class="line">   172.16.145.45:50010 (DN12)</span><br><span class="line">   172.16.145.60:50010 (DN23)</span><br><span class="line">   172.16.145.62:50010 (DN25)</span><br><span class="line"> </span><br><span class="line">Rack: /rack3</span><br><span class="line">   172.16.145.37:50010 (DN04)</span><br><span class="line">   172.16.145.51:50010 (DN14)</span><br><span class="line">   172.16.145.53:50010 (DN16)</span><br><span class="line">   172.16.145.55:50010 (DN18)</span><br><span class="line">   172.16.145.57:50010 (DN20)</span><br><span class="line"> </span><br><span class="line">Rack: /rack4</span><br><span class="line">   172.16.145.34:50010 (DN01)</span><br><span class="line">   172.16.145.35:50010 (DN02)</span><br><span class="line">   172.16.145.39:50010 (DN06)</span><br><span class="line">   172.16.145.50:50010 (DN13)</span><br><span class="line">   172.16.145.52:50010 (DN15)</span><br><span class="line">   172.16.145.59:50010 (DN22)</span><br><span class="line">   172.16.145.61:50010 (DN24)</span><br></pre></td></tr></table></figure>

<p><strong>hdfs 三个副本的这种存放策略减少了机架间的数据传输，提高了写操作的效率。机架的错误远远比节点的错误少，所以这种策略不会影响到数据的可靠性和可用性。与此同时，因为数据块只存放在两个不同的机架上，所以此策略减少了读取数据时需要的网络传输总带宽。在这种策略下，副本并不是均匀的分布在不同的机架上，这种策略在不损害数据可靠性和读取性能的情况下改进了写的性能。</strong></p>
<h2 id="读出数据"><a href="#读出数据" class="headerlink" title="读出数据"></a>读出数据</h2><p><img src="/HDFS/48.png" alt="48"></p>
<p>1）客户端通过Distributed FileSystem向NameNode请求下载文件，NameNode通过查询元数据，找到文件块所在的DataNode地址。</p>
<p>2）挑选一台DataNode（就近原则，然后随机）服务器，请求读取数据。</p>
<p>3）DataNode开始传输数据给客户端（从磁盘里面读取数据输入流，以Packet为单位来做校验）。</p>
<p>4）客户端以Packet为单位接收，先在本地缓存，然后写入目标文件。</p>
<h1 id="NameNode和SecondaryNameNode"><a href="#NameNode和SecondaryNameNode" class="headerlink" title="NameNode和SecondaryNameNode"></a>NameNode和SecondaryNameNode</h1><h2 id="NN和2NN工作机制"><a href="#NN和2NN工作机制" class="headerlink" title="NN和2NN工作机制"></a>NN和2NN工作机制</h2><p>思考：<strong>NameNode中的元数据是存储在哪里的</strong>？</p>
<p>首先，我们做个假设，如果存储在NameNode节点的磁盘中，因为经常需要进行随机访问，还有响应客户请求，必然是效率过低。因此，元数据需要存放在内存中。但如果只存在内存中，一旦断电，元数据丢失，整个集群就无法工作了。因此产生在磁盘中备份元数据的Fsimage。</p>
<p>这样又会带来新的问题，当在内存中的元数据更新时，如果同时更新Fsimage，就会导致效率过低，但如果不更新，就会发生一致性问题，一旦NameNode节点断电，就会产生数据丢失。因此，引入<strong>Edits文件(只进行追加操作，效率很高)<strong>。</strong>每当元数据有更新或者添加元数据时，修改内存中的元数据并追加到Edits中</strong>。这样，一旦NameNode节点断电，可以通过Fsimage和Edits的合并，合成元数据。</p>
<p>但是，如果长时间添加数据到Edits中，会导致该文件数据过大，效率降低，而且一旦断电，恢复元数据需要的时间过长。因此，需要<strong>定期进行Fsimage和Edits的合并</strong>，如果这个操作由NameNode节点完成，又会效率过低。因此，引入一个新的节点<strong>SecondaryNamenode，专门用于FsImage和Edits的合并</strong>。</p>
<p><img src="/HDFS/49.png" alt="49"></p>
<ol>
<li>第一阶段：NameNode启动</li>
</ol>
<p>（1）第一次启动NameNode格式化后，创建Fsimage和Edits文件。如果不是第一次启动，直接加载编辑日志和镜像文件到内存。</p>
<p>（2）客户端对元数据进行增删改的请求。</p>
<p>（3）NameNode记录操作日志，更新滚动日志。</p>
<p>（4）NameNode在内存中对元数据进行增删改。</p>
<ol start="2">
<li>第二阶段：Secondary NameNode工作</li>
</ol>
<p>（1）Secondary NameNode询问NameNode是否需要CheckPoint。直接带回NameNode是否检查结果。</p>
<p>（2）Secondary NameNode请求执行CheckPoint。</p>
<p>（3）NameNode滚动正在写的Edits日志。</p>
<p>（4）将滚动前的编辑日志和镜像文件拷贝到Secondary NameNode。</p>
<p>（5）Secondary NameNode加载编辑日志和镜像文件到内存，并合并。</p>
<p>（6）生成新的镜像文件fsimage.chkpoint。</p>
<p>（7）拷贝fsimage.chkpoint到NameNode。</p>
<p>（8）NameNode将fsimage.chkpoint重新命名成fsimage。</p>
<p>NN和2NN工作机制详解：</p>
<p><strong>Fsimage：NameNode内存中元数据序列化后形成的文件。</strong><br><strong>Edits：记录客户端更新元数据信息的每一步操作（可通过Edits运算出元数据）。</strong></p>
<p>NameNode启动时，先滚动Edits并生成一个空的edits.inprogress，然后加载Edits和Fsimage到内存中，此时NameNode内存就持有最新的元数据信息。Client开始对NameNode发送元数据的增删改的请求，这些请求的操作首先会被记录到edits.inprogress中（<strong>查询元数据的操作不会被记录在Edits中，因为查询操作不会更改元数据信息</strong>），如果此时NameNode挂掉，重启后会从Edits中读取元数据的信息。然后，NameNode会在内存中执行元数据的增删改的操作。<br>由于Edits中记录的操作会越来越多，Edits文件会越来越大，导致NameNode在启动加载Edits时会很慢，所以需要对Edits和Fsimage进行合并（所谓合并，就是将Edits和Fsimage加载到内存中，照着Edits中的操作一步步执行，最终形成新的Fsimage）。<strong>SecondaryNameNode的作用就是帮助NameNode进行Edits和Fsimage的合并工作。</strong><br>SecondaryNameNode首先会询问NameNode是否需要CheckPoint（触发CheckPoint需要满足两个条件中的任意一个，定时时间到和Edits中数据写满了）。直接带回NameNode是否检查结果。SecondaryNameNode执行CheckPoint操作，首先会让NameNode滚动Edits并生成一个空的edits.inprogress，滚动Edits的目的是给Edits打个标记，以后所有新的操作都写入edits.inprogress，其他未合并的Edits和Fsimage会拷贝到SecondaryNameNode的本地，然后将拷贝的Edits和Fsimage加载到内存中进行合并，生成fsimage.chkpoint，然后将fsimage.chkpoint拷贝给NameNode，重命名为Fsimage后替换掉原来的Fsimage。NameNode在启动时就只需要加载之前未合并的Edits和Fsimage即可，因为合并过的Edits中的元数据信息已经被记录在Fsimage中。</p>
<h2 id="Fsimage和Edits解析"><a href="#Fsimage和Edits解析" class="headerlink" title="Fsimage和Edits解析"></a>Fsimage和Edits解析</h2><p><img src="/HDFS/50.png" alt="50"></p>
<h3 id="oiv查看Fsimage文件"><a href="#oiv查看Fsimage文件" class="headerlink" title="oiv查看Fsimage文件"></a>oiv查看Fsimage文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">hdfs oiv -p 文件类型 -i 镜像文件 -o 转换后文件输出路径</span><br><span class="line"></span><br><span class="line">[vincent@linux1 current]$ pwd</span><br><span class="line">/opt/module/hadoop-3.1.3/data/tmp/dfs/name/current</span><br><span class="line"></span><br><span class="line">[vincent@linux1 current]$ hdfs oiv -p XML -i fsimage_0000000000000000025 -o /opt/module/hadoop-3.1.3/fsimage.xml</span><br><span class="line"></span><br><span class="line">[vincent@linux1 current]$ cat /opt/module/hadoop-3.1.3/fsimage.xml</span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">id</span>&gt;</span>16386<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">type</span>&gt;</span>DIRECTORY<span class="tag">&lt;/<span class="name">type</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>user<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1512722284477<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">permission</span>&gt;</span>vincent:supergroup:rwxr-xr-x<span class="tag">&lt;/<span class="name">permission</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">nsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">nsquota</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">dsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">dsquota</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">id</span>&gt;</span>16387<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">type</span>&gt;</span>DIRECTORY<span class="tag">&lt;/<span class="name">type</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>vincent<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1512790549080<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">permission</span>&gt;</span>vincent:supergroup:rwxr-xr-x<span class="tag">&lt;/<span class="name">permission</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">nsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">nsquota</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">dsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">dsquota</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">id</span>&gt;</span>16389<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">type</span>&gt;</span>FILE<span class="tag">&lt;/<span class="name">type</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>wc.input<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">replication</span>&gt;</span>3<span class="tag">&lt;/<span class="name">replication</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1512722322219<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">atime</span>&gt;</span>1512722321610<span class="tag">&lt;/<span class="name">atime</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">perferredBlockSize</span>&gt;</span>134217728<span class="tag">&lt;/<span class="name">perferredBlockSize</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">permission</span>&gt;</span>vincent:supergroup:rw-r--r--<span class="tag">&lt;/<span class="name">permission</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">blocks</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">block</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">id</span>&gt;</span>1073741825<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">genstamp</span>&gt;</span>1001<span class="tag">&lt;/<span class="name">genstamp</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">numBytes</span>&gt;</span>59<span class="tag">&lt;/<span class="name">numBytes</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">block</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">blocks</span>&gt;</span></span><br><span class="line">&lt;/inode &gt;</span><br></pre></td></tr></table></figure>

<p>Fsimage中没有记录块所对应DataNode，为什么？</p>
<p>在集群启动后，要求DataNode上报数据块信息，并间隔一段时间后再次上报。</p>
<h3 id="oev查看Edits文件"><a href="#oev查看Edits文件" class="headerlink" title="oev查看Edits文件"></a>oev查看Edits文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hdfs oev -p 文件类型 -i 编辑日志 -o 转换后文件输出路径</span><br><span class="line"></span><br><span class="line">[vincent@hadoop102 current]$ hdfs oev -p XML -i edits_0000000000000000012-0000000000000000013 -o /opt/module/hadoop-3.1.3/edits.xml</span><br><span class="line"></span><br><span class="line">[vincent@linux1 current]$ cat /opt/module/hadoop-3.1.3/edits.xml</span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">EDITS</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">EDITS_VERSION</span>&gt;</span>-63<span class="tag">&lt;/<span class="name">EDITS_VERSION</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">RECORD</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">OPCODE</span>&gt;</span>OP_START_LOG_SEGMENT<span class="tag">&lt;/<span class="name">OPCODE</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">DATA</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">TXID</span>&gt;</span>129<span class="tag">&lt;/<span class="name">TXID</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">DATA</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">RECORD</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">RECORD</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">OPCODE</span>&gt;</span>OP_ADD<span class="tag">&lt;/<span class="name">OPCODE</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">DATA</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">TXID</span>&gt;</span>130<span class="tag">&lt;/<span class="name">TXID</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">LENGTH</span>&gt;</span>0<span class="tag">&lt;/<span class="name">LENGTH</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">INODEID</span>&gt;</span>16407<span class="tag">&lt;/<span class="name">INODEID</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">PATH</span>&gt;</span>/hello7.txt<span class="tag">&lt;/<span class="name">PATH</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">REPLICATION</span>&gt;</span>2<span class="tag">&lt;/<span class="name">REPLICATION</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">MTIME</span>&gt;</span>1512943607866<span class="tag">&lt;/<span class="name">MTIME</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">ATIME</span>&gt;</span>1512943607866<span class="tag">&lt;/<span class="name">ATIME</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">BLOCKSIZE</span>&gt;</span>134217728<span class="tag">&lt;/<span class="name">BLOCKSIZE</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">CLIENT_NAME</span>&gt;</span>DFSClient_NONMAPREDUCE_-1544295051_1<span class="tag">&lt;/<span class="name">CLIENT_NAME</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">CLIENT_MACHINE</span>&gt;</span>192.168.1.5<span class="tag">&lt;/<span class="name">CLIENT_MACHINE</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">OVERWRITE</span>&gt;</span>true<span class="tag">&lt;/<span class="name">OVERWRITE</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">PERMISSION_STATUS</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">USERNAME</span>&gt;</span>vincent<span class="tag">&lt;/<span class="name">USERNAME</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">GROUPNAME</span>&gt;</span>supergroup<span class="tag">&lt;/<span class="name">GROUPNAME</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">MODE</span>&gt;</span>420<span class="tag">&lt;/<span class="name">MODE</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;/<span class="name">PERMISSION_STATUS</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">RPC_CLIENTID</span>&gt;</span>908eafd4-9aec-4288-96f1-e8011d181561<span class="tag">&lt;/<span class="name">RPC_CLIENTID</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">RPC_CALLID</span>&gt;</span>0<span class="tag">&lt;/<span class="name">RPC_CALLID</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">DATA</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">RECORD</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">RECORD</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">OPCODE</span>&gt;</span>OP_ALLOCATE_BLOCK_ID<span class="tag">&lt;/<span class="name">OPCODE</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">DATA</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">TXID</span>&gt;</span>131<span class="tag">&lt;/<span class="name">TXID</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">BLOCK_ID</span>&gt;</span>1073741839<span class="tag">&lt;/<span class="name">BLOCK_ID</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">DATA</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">RECORD</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">RECORD</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">OPCODE</span>&gt;</span>OP_SET_GENSTAMP_V2<span class="tag">&lt;/<span class="name">OPCODE</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">DATA</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">TXID</span>&gt;</span>132<span class="tag">&lt;/<span class="name">TXID</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">GENSTAMPV2</span>&gt;</span>1016<span class="tag">&lt;/<span class="name">GENSTAMPV2</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">DATA</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">RECORD</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">RECORD</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">OPCODE</span>&gt;</span>OP_ADD_BLOCK<span class="tag">&lt;/<span class="name">OPCODE</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">DATA</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">TXID</span>&gt;</span>133<span class="tag">&lt;/<span class="name">TXID</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">PATH</span>&gt;</span>/hello7.txt<span class="tag">&lt;/<span class="name">PATH</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">BLOCK</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">BLOCK_ID</span>&gt;</span>1073741839<span class="tag">&lt;/<span class="name">BLOCK_ID</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">NUM_BYTES</span>&gt;</span>0<span class="tag">&lt;/<span class="name">NUM_BYTES</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">GENSTAMP</span>&gt;</span>1016<span class="tag">&lt;/<span class="name">GENSTAMP</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;/<span class="name">BLOCK</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">RPC_CLIENTID</span>&gt;</span><span class="tag">&lt;/<span class="name">RPC_CLIENTID</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">RPC_CALLID</span>&gt;</span>-2<span class="tag">&lt;/<span class="name">RPC_CALLID</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">DATA</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">RECORD</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">RECORD</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">OPCODE</span>&gt;</span>OP_CLOSE<span class="tag">&lt;/<span class="name">OPCODE</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">DATA</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">TXID</span>&gt;</span>134<span class="tag">&lt;/<span class="name">TXID</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">LENGTH</span>&gt;</span>0<span class="tag">&lt;/<span class="name">LENGTH</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">INODEID</span>&gt;</span>0<span class="tag">&lt;/<span class="name">INODEID</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">PATH</span>&gt;</span>/hello7.txt<span class="tag">&lt;/<span class="name">PATH</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">REPLICATION</span>&gt;</span>2<span class="tag">&lt;/<span class="name">REPLICATION</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">MTIME</span>&gt;</span>1512943608761<span class="tag">&lt;/<span class="name">MTIME</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">ATIME</span>&gt;</span>1512943607866<span class="tag">&lt;/<span class="name">ATIME</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">BLOCKSIZE</span>&gt;</span>134217728<span class="tag">&lt;/<span class="name">BLOCKSIZE</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">CLIENT_NAME</span>&gt;</span><span class="tag">&lt;/<span class="name">CLIENT_NAME</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">CLIENT_MACHINE</span>&gt;</span><span class="tag">&lt;/<span class="name">CLIENT_MACHINE</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">OVERWRITE</span>&gt;</span>false<span class="tag">&lt;/<span class="name">OVERWRITE</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">BLOCK</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">BLOCK_ID</span>&gt;</span>1073741839<span class="tag">&lt;/<span class="name">BLOCK_ID</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">NUM_BYTES</span>&gt;</span>25<span class="tag">&lt;/<span class="name">NUM_BYTES</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">GENSTAMP</span>&gt;</span>1016<span class="tag">&lt;/<span class="name">GENSTAMP</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;/<span class="name">BLOCK</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">PERMISSION_STATUS</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">USERNAME</span>&gt;</span>vincent<span class="tag">&lt;/<span class="name">USERNAME</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">GROUPNAME</span>&gt;</span>supergroup<span class="tag">&lt;/<span class="name">GROUPNAME</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">MODE</span>&gt;</span>420<span class="tag">&lt;/<span class="name">MODE</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;/<span class="name">PERMISSION_STATUS</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">DATA</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">RECORD</span>&gt;</span></span><br><span class="line">&lt;/EDITS &gt;</span><br></pre></td></tr></table></figure>

<h2 id="CheckPoint时间设置"><a href="#CheckPoint时间设置" class="headerlink" title="CheckPoint时间设置"></a>CheckPoint时间设置</h2><p>（1）通常情况下，SecondaryNameNode每隔一小时执行一次。</p>
<p>hdfs-default.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.checkpoint.period<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>3600<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>（2）一分钟检查一次操作次数，3当操作次数达到1百万时，SecondaryNameNode执行一次。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.checkpoint.txns<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>1000000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">description</span>&gt;</span>操作动作次数<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.checkpoint.check.period<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>60<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">description</span>&gt;</span> 1分钟检查一次操作次数<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="NameNode故障处理"><a href="#NameNode故障处理" class="headerlink" title="NameNode故障处理"></a>NameNode故障处理</h2><p><strong>方法一：将SecondaryNameNode中数据拷贝到NameNode存储数据的目录</strong></p>
<ol>
<li><p>kill -9 NameNode进程</p>
</li>
<li><p>删除NameNode存储的数据（/opt/module/hadoop-3.1.3/data/name）</p>
</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm -rf /opt/module/hadoop-3.1.3/data/name/*</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>拷贝SecondaryNameNode中数据到原NameNode存储数据目录</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp -r vincent@linux3:/opt/module/hadoop-3.1.3/data/namesecondary/* /opt/module/hadoop-3.1.3/data/name/</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>重新启动NameNode</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs --daemon start namenode</span><br></pre></td></tr></table></figure>

<p><strong>方法二：使用-importCheckpoint选项启动NameNode守护进程，从而将SecondaryNameNode中数据拷贝到NameNode目录中</strong></p>
<ol>
<li>修改hdfs-site.xml中的</li>
</ol>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.checkpoint.period<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>120<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-3.1.3/data/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ol start="2">
<li><p>kill -9 NameNode进程</p>
</li>
<li><p>删除NameNode存储的数据（/opt/module/hadoop-3.1.3/data/name）</p>
</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[vincent@linux1 hadoop-3.1.3]$ rm -rf /opt/module/hadoop-3.1.3/data/name/*</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>如果SecondaryNameNode不和NameNode在一个主机节点上，需要将SecondaryNameNode存储数据的目录拷贝到NameNode存储数据的平级目录，并删除in_use.lock文件</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[vincent@linux1 data]$ scp -r vincent@linux3:/opt/module/hadoop-3.1.3/data/namesecondary ./</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 在linux1中删除拷贝过来的in_use.lock</span></span><br><span class="line">[vincent@linux1 namesecondary]$ rm -rf in_use.lock</span><br><span class="line"></span><br><span class="line">[vincent@linux1 data]$ pwd</span><br><span class="line">/opt/module/hadoop-3.1.3/data</span><br><span class="line"></span><br><span class="line">[vincent@linux1 data]$ ls</span><br><span class="line">data  name  namesecondary</span><br></pre></td></tr></table></figure>

<ol start="5">
<li>   导入检查点数据（等待一会ctrl+c结束掉）</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[vincent@linux1 hadoop-3.1.3]$ bin/hdfs namenode -importCheckpoint</span><br></pre></td></tr></table></figure>

<ol start="6">
<li>   启动NameNode</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[vincent@linux1 hadoop-3.1.3]$ hdfs --daemon start namenode</span><br></pre></td></tr></table></figure>

<h2 id="集群安全模式"><a href="#集群安全模式" class="headerlink" title="集群安全模式"></a>集群安全模式</h2><p><img src="/HDFS/51.png" alt="51"></p>
<p>集群处于安全模式，不能执行重要操作（写操作）。集群启动完成后，自动退出安全模式。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">bin/hdfs dfsadmin -safemode get		（功能描述：查看安全模式状态）</span><br><span class="line">bin/hdfs dfsadmin -safemode enter  （功能描述：进入安全模式状态）</span><br><span class="line">bin/hdfs dfsadmin -safemode leave	（功能描述：离开安全模式状态）</span><br><span class="line">bin/hdfs dfsadmin -safemode wait	（功能描述：等待安全模式状态）</span><br></pre></td></tr></table></figure>

<h2 id="NameNode多目录配置"><a href="#NameNode多目录配置" class="headerlink" title="NameNode多目录配置"></a>NameNode多目录配置</h2><ol>
<li><p>NameNode的本地目录可以配置成多个，且每个目录存放内容相同，增加了可靠性</p>
</li>
<li><p>具体配置如下</p>
<p>1）在hdfs-site.xml文件中修改如下内容</p>
</li>
</ol>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///$&#123;hadoop.tmp.dir&#125;/name1,file:///$&#123;hadoop.tmp.dir&#125;/name2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>​        2）停止集群，删除data和logs中所有数据。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[vincent@linux1 hadoop-3.1.3]$ rm -rf data/ logs/</span><br><span class="line">[vincent@linux2 hadoop-3.1.3]$ rm -rf data/ logs/</span><br><span class="line">[vincent@linux3 hadoop-3.1.3]$ rm -rf data/ logs/</span><br></pre></td></tr></table></figure>

<p>​        3）格式化集群并启动</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[vincent@linux1 hadoop-3.1.3]$ bin/hdfs namenode –format</span><br><span class="line">[vincent@linux1 hadoop-3.1.3]$ sbin/start-dfs.sh</span><br></pre></td></tr></table></figure>

<p>​        4）查看结果</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[vincent@linux1 data]$ ll</span><br><span class="line">总用量 12</span><br><span class="line">drwx------. 3 vincent vincent 4096 12月 11 08:03 data</span><br><span class="line">drwxrwxr-x. 3 vincent vincent 4096 12月 11 08:03 name1</span><br><span class="line">drwxrwxr-x. 3 vincent vincent 4096 12月 11 08:03 name2</span><br></pre></td></tr></table></figure>

<h1 id="DataNode"><a href="#DataNode" class="headerlink" title="DataNode"></a>DataNode</h1><h2 id="DataNode工作机制"><a href="#DataNode工作机制" class="headerlink" title="DataNode工作机制"></a>DataNode工作机制</h2><p><img src="/HDFS/52.png" alt="52"></p>
<p>1）<strong>一个数据块在DataNode上以文件形式存储在磁盘上，包括两个文件，一个是数据本身，一个是元数据</strong>包括数据块的长度，块数据的校验和，以及时间戳。</p>
<p>2）DataNode启动后向NameNode注册，通过后，周期性（1小时）的向NameNode上报所有的块信息。</p>
<p>3）<strong>心跳是每3秒一次</strong>，心跳返回结果带有NameNode给该DataNode的命令如复制块数据到另一台机器，或删除某个数据块。<strong>如果超过10分钟30秒没有收到某个DataNode的心跳，则认为该节点不可用。</strong></p>
<p>4）集群运行中可以安全加入和退出一些机器。</p>
<h2 id="数据完整性"><a href="#数据完整性" class="headerlink" title="数据完整性"></a>数据完整性</h2><p><img src="/HDFS/53.png" alt="53"></p>
<p>思考：如果电脑磁盘里面存储的数据是控制高铁信号灯的红灯信号（1）和绿灯信号（0），但是存储该数据的磁盘坏了，一直显示是绿灯，是否很危险？同理DataNode节点上的数据损坏了，却没有发现，是否也很危险，那么如何解决呢？</p>
<p>如下是DataNode节点保证数据完整性的方法。</p>
<p>1）当DataNode读取Block的时候，它会计算CheckSum。</p>
<p>2）如果计算后的CheckSum，与Block创建时值不一样，说明Block已经损坏。</p>
<p>3）Client读取其他DataNode上的Block。</p>
<p>4）常见的校验算法 crc（32）  md5（128）  sha1（160）。</p>
<p>5）DataNode在其文件创建后周期验证CheckSum。</p>
<h2 id="掉线时限参数设置"><a href="#掉线时限参数设置" class="headerlink" title="掉线时限参数设置"></a>掉线时限参数设置</h2><p><img src="/HDFS/54.png" alt="54"></p>
<p>需要注意的是hdfs-site.xml 配置文件中的heartbeat.recheck.interval的单位为毫秒，dfs.heartbeat.interval的单位为秒。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.heartbeat.recheck-interval<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>300000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.heartbeat.interval<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="服役新数据节点"><a href="#服役新数据节点" class="headerlink" title="服役新数据节点"></a>服役新数据节点</h2><p>1.在新节点中进行操作系统配置，包括主机名、网络、防火墙和无密码登录等。</p>
<p>2.在所有节点/etc/hosts文件中添加新节点。</p>
<p>3.把namenode的有关配置文件复制到该节点。</p>
<p>4.修改master节点slaves/works文件,增加该节点。</p>
<p>5.单独启动该节点上的datanode和nodemanager</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[vincent@linux4 hadoop-3.1.3]$ hdfs --daemon start datanode</span><br><span class="line">[vincent@linux4 hadoop-3.1.3]$ yarn --daemon start nodemanager</span><br></pre></td></tr></table></figure>

<p>6.运行start-balancer.sh 进行数据负载均衡</p>
<p>（默认阀值:单个节点的使用率和整个集群的使用率差值是10%以下,超过百分之十集群就会进行负载均衡）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[vincent@linux4 hadoop-3.1.3]$ sbin/start-balancer.sh</span><br></pre></td></tr></table></figure>

<h2 id="退役旧数据节点"><a href="#退役旧数据节点" class="headerlink" title="退役旧数据节点"></a>退役旧数据节点</h2><p>添加到白名单或者黑名单。</p>
<p>添加到白名单的主机节点，都允许访问NameNode，不在白名单的主机节点，都会被直接退出。</p>
<p>添加到黑名单的主机节点，不允许访问NameNode，会在数据迁移后退出。</p>
<p>实际情况下，白名单用于确定允许访问NameNode的DataNode节点，内容配置一般与workers文件内容一致。 黑名单用于在集群运行过程中退役DataNode节点。</p>
<p>配置白名单和黑名单的具体步骤如下：</p>
<p>（1）在NameNode的/opt/module/hadoop-3.1.3/etc/hadoop目录下分别创建whitelist 和 blacklist 文件</p>
<p>在whitelist中添加如下主机名称,假如集群正常工作的节点为linux1，linux2，linux3</p>
<figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">li<span class="symbol">nux1</span></span><br><span class="line">li<span class="symbol">nux2</span></span><br><span class="line">li<span class="symbol">nux3</span></span><br></pre></td></tr></table></figure>

<p>黑名单暂时为空。</p>
<p>（2）在NameNode的hdfs-site.xml配置文件中增加dfs.hosts 和 dfs.hosts.exclude配置</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- whitelist --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.hosts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-3.1.3/etc/hadoop/whitelist<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- blacklist --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.hosts.exclude<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-3.1.3/etc/hadoop/blacklist<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>（3）配置文件分发</p>
<p>（4）重新启动集群</p>
<p>白名单退役会直接将节点抛弃，没有迁移数据的过程，会造成数据丢失。</p>
<p>黑名单会进行数据迁移，推荐使用黑名单。</p>
<h2 id="Datanode多目录配置"><a href="#Datanode多目录配置" class="headerlink" title="Datanode多目录配置"></a>Datanode多目录配置</h2><ol>
<li><p>DataNode也可以配置成多个目录，每个目录存储的数据不一样。即：数据不是副本。</p>
</li>
<li><p>具体配置如下</p>
</li>
</ol>
<p>（1）在hdfs-site.xml中修改如下内容:</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///$&#123;hadoop.tmp.dir&#125;/data1,file:///$&#123;hadoop.tmp.dir&#125;/data2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>（2）停止集群，删除data和logs中所有数据。</p>
<p>（3）格式化集群并启动。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[vincent@linux1 hadoop-3.1.3]$ bin/hdfs namenode -format</span><br><span class="line">[vincent@linux1 hadoop-3.1.3]$ sbin/start-dfs.sh</span><br></pre></td></tr></table></figure>

<h1 id="小文件存档"><a href="#小文件存档" class="headerlink" title="小文件存档"></a>小文件存档</h1><p><img src="/HDFS/55.png" alt="55"></p>
<p>1.归档文件:</p>
<p>把/user/vincent/input目录里面的所有文件归档成一个叫input.har的归档文件，并把归档后文件存储到/user/vincent/output路径下</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[vincent@linux1 hadoop-3.1.3]$ bin/hadoop archive -archiveName input.har -p  /user/vincent/input /user/vincent/output</span><br></pre></td></tr></table></figure>

<p>2.查看归档</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[vincent@linux1 hadoop-3.1.3]$ hadoop fs -lsr /user/vincent/output/input.har</span><br><span class="line">[vincent@linux1 hadoop-3.1.3]$ hadoop fs -lsr har:///user/vincent/output/input.har</span><br></pre></td></tr></table></figure>

<p>3.解归档文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[vincent@linux1 hadoop-3.1.3]$ hadoop fs -cp har:///user/vincent/output/input.har/* /user/vincent</span><br></pre></td></tr></table></figure>


    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/Hbase/" rel="prev" title="Hbase">
      <i class="fa fa-chevron-left"></i> Hbase
    </a></div>
      <div class="post-nav-item">
    <a href="/Hadoop%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/" rel="next" title="HDFS配置">
      HDFS配置 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#HDFS%E6%A6%82%E8%BF%B0"><span class="nav-number">1.</span> <span class="nav-text">HDFS概述</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="nav-number">2.</span> <span class="nav-text">优缺点</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%9E%B6%E6%9E%84"><span class="nav-number">3.</span> <span class="nav-text">架构</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%96%87%E4%BB%B6%E5%9D%97%E5%A4%A7%E5%B0%8F"><span class="nav-number">4.</span> <span class="nav-text">文件块大小</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Shell%E6%93%8D%E4%BD%9C"><span class="nav-number">5.</span> <span class="nav-text">Shell操作</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#HDFS%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%9D%83%E9%99%90"><span class="nav-number">6.</span> <span class="nav-text">HDFS客户端权限</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#HDFS%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%93%8D%E4%BD%9C"><span class="nav-number">7.</span> <span class="nav-text">HDFS客户端操作</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%87%86%E5%A4%87%E6%93%8D%E4%BD%9C"><span class="nav-number">7.1.</span> <span class="nav-text">准备操作</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#API%E6%93%8D%E4%BD%9C"><span class="nav-number">7.2.</span> <span class="nav-text">API操作</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#HDFS%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%EF%BC%88%E6%B5%8B%E8%AF%95%E5%8F%82%E6%95%B0%E4%BC%98%E5%85%88%E7%BA%A7%EF%BC%89"><span class="nav-number">7.2.1.</span> <span class="nav-text">HDFS文件上传（测试参数优先级）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HDFS%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD"><span class="nav-number">7.2.2.</span> <span class="nav-text">HDFS文件下载</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HDFS%E6%96%87%E4%BB%B6%E5%A4%B9%E5%88%A0%E9%99%A4"><span class="nav-number">7.2.3.</span> <span class="nav-text">HDFS文件夹删除</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HDFS%E6%96%87%E4%BB%B6%E5%90%8D%E6%9B%B4%E6%94%B9-%E7%A7%BB%E5%8A%A8"><span class="nav-number">7.2.4.</span> <span class="nav-text">HDFS文件名更改&#x2F;移动</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HDFS%E6%96%87%E4%BB%B6%E8%AF%A6%E6%83%85%E6%9F%A5%E7%9C%8B"><span class="nav-number">7.2.5.</span> <span class="nav-text">HDFS文件详情查看</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HDFS%E6%96%87%E4%BB%B6%E5%92%8C%E6%96%87%E4%BB%B6%E5%A4%B9%E5%88%A4%E6%96%AD"><span class="nav-number">7.2.6.</span> <span class="nav-text">HDFS文件和文件夹判断</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#HDFS%E7%9A%84%E6%95%B0%E6%8D%AE%E6%B5%81"><span class="nav-number">8.</span> <span class="nav-text">HDFS的数据流</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%86%99%E5%85%A5%E6%95%B0%E6%8D%AE"><span class="nav-number">8.1.</span> <span class="nav-text">写入数据</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BD%91%E7%BB%9C%E6%8B%93%E6%89%91-%E8%8A%82%E7%82%B9%E8%B7%9D%E7%A6%BB%E8%AE%A1%E7%AE%97"><span class="nav-number">8.1.1.</span> <span class="nav-text">网络拓扑-节点距离计算</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%89%AF%E6%9C%AC%E8%8A%82%E7%82%B9%E9%80%89%E6%8B%A9"><span class="nav-number">8.1.2.</span> <span class="nav-text">副本节点选择</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%BA%E6%9E%B6%E6%84%9F%E7%9F%A5"><span class="nav-number">8.1.3.</span> <span class="nav-text">机架感知</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AF%BB%E5%87%BA%E6%95%B0%E6%8D%AE"><span class="nav-number">8.2.</span> <span class="nav-text">读出数据</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#NameNode%E5%92%8CSecondaryNameNode"><span class="nav-number">9.</span> <span class="nav-text">NameNode和SecondaryNameNode</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#NN%E5%92%8C2NN%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6"><span class="nav-number">9.1.</span> <span class="nav-text">NN和2NN工作机制</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Fsimage%E5%92%8CEdits%E8%A7%A3%E6%9E%90"><span class="nav-number">9.2.</span> <span class="nav-text">Fsimage和Edits解析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#oiv%E6%9F%A5%E7%9C%8BFsimage%E6%96%87%E4%BB%B6"><span class="nav-number">9.2.1.</span> <span class="nav-text">oiv查看Fsimage文件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#oev%E6%9F%A5%E7%9C%8BEdits%E6%96%87%E4%BB%B6"><span class="nav-number">9.2.2.</span> <span class="nav-text">oev查看Edits文件</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CheckPoint%E6%97%B6%E9%97%B4%E8%AE%BE%E7%BD%AE"><span class="nav-number">9.3.</span> <span class="nav-text">CheckPoint时间设置</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#NameNode%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86"><span class="nav-number">9.4.</span> <span class="nav-text">NameNode故障处理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%9B%86%E7%BE%A4%E5%AE%89%E5%85%A8%E6%A8%A1%E5%BC%8F"><span class="nav-number">9.5.</span> <span class="nav-text">集群安全模式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#NameNode%E5%A4%9A%E7%9B%AE%E5%BD%95%E9%85%8D%E7%BD%AE"><span class="nav-number">9.6.</span> <span class="nav-text">NameNode多目录配置</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#DataNode"><span class="nav-number">10.</span> <span class="nav-text">DataNode</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#DataNode%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6"><span class="nav-number">10.1.</span> <span class="nav-text">DataNode工作机制</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%95%B4%E6%80%A7"><span class="nav-number">10.2.</span> <span class="nav-text">数据完整性</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8E%89%E7%BA%BF%E6%97%B6%E9%99%90%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE"><span class="nav-number">10.3.</span> <span class="nav-text">掉线时限参数设置</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%8D%E5%BD%B9%E6%96%B0%E6%95%B0%E6%8D%AE%E8%8A%82%E7%82%B9"><span class="nav-number">10.4.</span> <span class="nav-text">服役新数据节点</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%80%80%E5%BD%B9%E6%97%A7%E6%95%B0%E6%8D%AE%E8%8A%82%E7%82%B9"><span class="nav-number">10.5.</span> <span class="nav-text">退役旧数据节点</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Datanode%E5%A4%9A%E7%9B%AE%E5%BD%95%E9%85%8D%E7%BD%AE"><span class="nav-number">10.6.</span> <span class="nav-text">Datanode多目录配置</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%B0%8F%E6%96%87%E4%BB%B6%E5%AD%98%E6%A1%A3"><span class="nav-number">11.</span> <span class="nav-text">小文件存档</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Vincent"
      src="/images/cute.jpeg">
  <p class="site-author-name" itemprop="name">Vincent</p>
  <div class="site-description" itemprop="description">nice</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">18</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Vincent</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

</body>
</html>
